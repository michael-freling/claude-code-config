---
name: docker
description: Docker and containerization development following best practices for Dockerfile creation, multi-stage builds, security, optimization, and container orchestration. Use when creating or updating Dockerfiles, Containerfiles, or docker-compose.yml files.
allowed-tools: [Read, Write, Edit, Glob, Grep, Bash]
---

# Docker Development Skill

A comprehensive skill for creating and updating Docker containers following 2025 best practices for security, optimization, and maintainability.

## When to Use

Use this skill when:
- Creating new Dockerfiles or Containerfiles
- Updating existing container configurations
- Optimizing Docker images for size and security
- Setting up multi-stage builds
- Creating docker-compose.yml files
- Need to follow Docker-specific security and optimization patterns

## Process

### 0. Read Project Design Documentation

**CRITICAL FIRST STEP: Always check for and read `.claude/docs/guideline.md`**

Before starting any implementation:

1. **Look for `.claude/docs/guideline.md` in the current directory**
   - If found, read it thoroughly
   - This contains project-specific coding standards, conventions, and architecture
   - Follow these guidelines strictly as they override general best practices

2. **For monorepos or subprojects:**
   - Check for `.claude/docs/guideline.md` in the subproject root
   - Also check the repository root for overall standards
   - Subproject-specific rules take precedence over repository-level rules

3. **If no guideline.md exists:**
   - Consider running `/document-guideline` to create one
   - Or proceed with analyzing the codebase manually

**What to extract from guideline.md:**
- Container naming conventions
- Base image preferences
- Security requirements
- Port conventions
- Volume mount patterns
- Environment variable conventions

### 1. Analyze Project Structure

- Identify the application type (Node.js, Go, Python, etc.)
- Check for existing Dockerfile or docker-compose.yml
- Review package manager files (package.json, go.mod, requirements.txt, etc.)
- Identify build requirements and runtime dependencies
- Check for .dockerignore file

### 2. Search for Relevant Configuration

- Look for existing container configurations
- Find similar Dockerfile implementations in the project
- Identify environment-specific configurations
- Check for CI/CD pipeline configurations

## Docker Best Practices

### General Principles

Following general coding guidelines:
1. **Simplicity**: Keep Dockerfiles simple and focused
2. **DRY (Don't Repeat Yourself)**: Use multi-stage builds to avoid duplication
3. **Consistency**: Follow project conventions from design.md
4. **Fail-fast**: Use `set -euo pipefail` in RUN commands with shell scripts
5. **Latest versions**: Use specific version tags (not :latest) but keep them current
6. **Encapsulation**: Keep containers single-purpose and minimal
7. **Comments**: Comments MUST BE about WHY not WHAT - explain reasoning, not what the code does

### Base Image Selection

- **Use official, minimal base images**: Prefer Alpine, Distroless, or slim variants
- **Pin to specific versions**: Use digest pinning (SHA256) for supply chain security
- **Avoid :latest tag**: Always specify exact version numbers
- **Consider security**: Smaller images have smaller attack surface

Example:
```dockerfile
# Good: Specific version with Alpine for minimal size
FROM node:18.20.2-alpine3.19

# Better: Pin to specific digest for reproducibility
FROM node:18.20.2-alpine3.19@sha256:abc123...

# Bad: Using latest tag (unpredictable)
FROM node:latest

# Bad: Using large base image when smaller works
FROM ubuntu:22.04
```

### Multi-Stage Builds

**CRITICAL: Always use multi-stage builds to reduce final image size by 50-85%**

Multi-stage builds separate build-time dependencies from runtime, resulting in:
- Significantly smaller images (companies report 50-85% size reduction)
- Improved security (fewer attack vectors)
- Faster deployment times
- Better layer caching

Example:
```dockerfile
# Build stage - includes all build tools
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files and install dependencies
COPY package.json pnpm-lock.yaml ./
RUN corepack enable pnpm && \
    pnpm install --frozen-lockfile

# Copy source and build
COPY . .
RUN pnpm run build

# Production stage - minimal runtime image
FROM node:18-alpine AS production

# Install tini for proper signal handling
RUN apk add --no-cache tini

WORKDIR /app

# Create non-root user
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001

# Copy only production dependencies
COPY --from=builder /app/package.json /app/pnpm-lock.yaml ./
RUN corepack enable pnpm && \
    pnpm install --prod --frozen-lockfile

# Copy built application
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist

# Environment variables
ENV NODE_ENV=production \
    PORT=3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:$PORT/health || exit 1

# Switch to non-root user
USER nextjs

EXPOSE $PORT

ENTRYPOINT ["tini", "--"]
CMD ["node", "dist/server.js"]
```

### Layer Caching Optimization

**Order instructions from least to most frequently changing**

Docker caches layers, so proper ordering maximizes cache hits:

1. Base image and system packages (least frequent)
2. Dependency files (package.json, go.mod, requirements.txt)
3. Dependency installation
4. Application source code (most frequent)

Example:
```dockerfile
# Good: Optimized layer ordering
FROM golang:1.22-alpine AS builder

WORKDIR /app

# 1. Copy dependency files first (changes less frequently)
COPY go.mod go.sum ./
RUN go mod download

# 2. Copy source code (changes more frequently)
COPY . .
RUN go build -o app .

# Bad: Copying everything at once (breaks cache on any file change)
FROM golang:1.22-alpine AS builder
WORKDIR /app
COPY . .
RUN go mod download && go build -o app .
```

### RUN Command Best Practices

**Handle errors and optimize layers**

1. **Use `set -euo pipefail`** for shell scripts to fail-fast
2. **Chain related commands** with `&&` to reduce layers
3. **Clean up in the same layer** to reduce image size
4. **Sort multi-line arguments** alphabetically for maintainability

Example:
```dockerfile
# Good: Single layer with error handling and cleanup
RUN set -euo pipefail && \
    apk add --no-cache \
        ca-certificates \
        curl \
        tzdata && \
    rm -rf /var/cache/apk/*

# Good: Debian/Ubuntu pattern - update and install in one layer
RUN set -euo pipefail && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
        ca-certificates \
        curl \
        git && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Bad: Multiple layers and no error handling
RUN apk add --no-cache ca-certificates
RUN apk add --no-cache curl
RUN apk add --no-cache tzdata

# Bad: Separate RUN for cleanup (doesn't reduce image size)
RUN apt-get update && apt-get install -y curl
RUN rm -rf /var/lib/apt/lists/*
```

### Security Best Practices

**58% of production containers run as root - don't be one of them**

1. **Run as non-root user**: Create and use a dedicated user
2. **Scan for vulnerabilities**: 87% of Docker images contain high/critical vulnerabilities
3. **Don't store secrets**: Never put credentials in Dockerfile, ENV, or ARG
4. **Minimize installed packages**: Only install what's needed
5. **Use .dockerignore**: Exclude unnecessary files from build context

Example:
```dockerfile
# Good: Complete security setup
FROM python:3.11-slim

# Create non-root user early
RUN groupadd -r appuser -g 1001 && \
    useradd -u 1001 -r -g appuser -m -s /sbin/nologin appuser

WORKDIR /app

# Install dependencies as root
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application with correct ownership
COPY --chown=appuser:appuser . .

# Switch to non-root user before runtime
USER appuser

CMD ["python", "app.py"]

# Bad: Running as root
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["python", "app.py"]  # Runs as root!
```

### .dockerignore File

**Exclude build context files to speed up builds and improve security**

Always create a `.dockerignore` file to exclude:
- Version control (.git, .svn)
- Development files (node_modules, .env, *.log)
- Documentation (README.md, docs/)
- CI/CD configs (.github/, .gitlab-ci.yml)

Example `.dockerignore`:
```
# Version control
.git
.gitignore
.gitattributes

# Dependencies (will be installed in container)
node_modules
vendor
__pycache__

# Development files
.env
.env.*
*.log
*.md
!README.md

# IDE
.vscode
.idea
*.swp

# CI/CD
.github
.gitlab-ci.yml
Jenkinsfile

# Testing
coverage
*.test
test-results

# Build artifacts
dist
build
*.exe
```

### COPY vs ADD

**Prefer COPY over ADD for explicit file operations**

- Use `COPY` for copying files and directories
- Only use `ADD` when you need automatic tar extraction or remote URL fetching
- `COPY` is more explicit and predictable

Example:
```dockerfile
# Good: Explicit COPY for files
COPY package.json pnpm-lock.yaml ./
COPY src/ ./src/

# Good: ADD for tar extraction (only valid use case)
ADD app.tar.gz /app/

# Bad: Using ADD for simple file copy
ADD package.json ./
```

### WORKDIR Best Practice

**Use WORKDIR instead of proliferating RUN cd commands**

- Sets working directory for subsequent instructions
- Creates directory if it doesn't exist
- More maintainable than cd commands

Example:
```dockerfile
# Good: Clear working directory
WORKDIR /app
COPY . .
RUN make build

# Bad: Using cd commands
RUN cd /app && make build
```

### ENTRYPOINT vs CMD

**Use ENTRYPOINT for the main executable, CMD for default arguments**

- `ENTRYPOINT`: The main command that always runs
- `CMD`: Default arguments that can be overridden
- Always use JSON array format (exec form) for proper signal handling
- Use `tini` or similar init system for PID 1 responsibilities

Example:
```dockerfile
# Good: ENTRYPOINT + CMD pattern
ENTRYPOINT ["tini", "--"]
CMD ["node", "server.js"]

# Good: Overridable behavior
ENTRYPOINT ["python", "app.py"]
CMD ["--port", "8080"]

# Good: Script as entrypoint
COPY docker-entrypoint.sh /
RUN chmod +x /docker-entrypoint.sh
ENTRYPOINT ["/docker-entrypoint.sh"]
CMD ["serve"]

# Bad: Shell form (doesn't handle signals properly)
ENTRYPOINT python app.py

# Bad: Everything in CMD (can't ensure main command runs)
CMD ["python", "app.py", "--port", "8080"]
```

### Environment Variables and Build Arguments

**Use ARG for build-time, ENV for runtime**

- `ARG`: Available only during build
- `ENV`: Available at runtime in the container
- Combine ARG with ENV if needed both at build and runtime
- Never put secrets in ARG or ENV

Example:
```dockerfile
# Good: Build and runtime variables
ARG NODE_VERSION=18
ARG BUILD_DATE

ENV NODE_ENV=production \
    APP_HOME=/app \
    PORT=8080

# Use ARG to set ENV
ARG VERSION=1.0.0
ENV APP_VERSION=${VERSION}

# Bad: Secrets in Dockerfile
ENV DATABASE_PASSWORD=secret123  # NEVER DO THIS
ARG API_KEY=abc123               # NEVER DO THIS

# Good: Expect secrets at runtime
ENV DATABASE_PASSWORD_FILE=/run/secrets/db_password
```

### HEALTHCHECK

**Always include health checks for production containers**

Configure with appropriate intervals and timeouts:
- `--interval`: Time between health checks (default: 30s)
- `--timeout`: Max time for check to complete (default: 30s)
- `--start-period`: Grace period for container startup (default: 0s)
- `--retries`: Consecutive failures needed to mark unhealthy (default: 3)

Example:
```dockerfile
# Good: HTTP health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8080/health || exit 1

# Good: Simple process check
HEALTHCHECK --interval=10s --timeout=2s --start-period=5s --retries=3 \
  CMD pgrep -f "python app.py" || exit 1

# Good: Custom health script
HEALTHCHECK --interval=30s --timeout=5s --start-period=10s --retries=3 \
  CMD /app/healthcheck.sh || exit 1

# Bad: Too frequent checks (wastes resources)
HEALTHCHECK --interval=1s CMD curl -f http://localhost:8080/health || exit 1

# Bad: No start period (fails during slow startup)
HEALTHCHECK --interval=30s CMD curl -f http://localhost:8080/health || exit 1
```

### LABEL for Metadata

**Add meaningful labels for organization and automation**

Use standardized labels for better container management:

Example:
```dockerfile
LABEL org.opencontainers.image.title="My Application" \
      org.opencontainers.image.description="Production API service" \
      org.opencontainers.image.version="1.0.0" \
      org.opencontainers.image.authors="team@example.com" \
      org.opencontainers.image.source="https://github.com/org/repo" \
      org.opencontainers.image.licenses="MIT"
```

### Language-Specific Best Practices

#### Go Applications

```dockerfile
# Multi-stage build for Go
FROM golang:1.22-alpine AS builder

WORKDIR /app

# Install build dependencies if needed
RUN apk add --no-cache git ca-certificates

# Copy go.mod and go.sum for layer caching
COPY go.mod go.sum ./
RUN go mod download

# Copy source code
COPY . .

# Build with optimizations
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -ldflags="-s -w" -o app .

# Minimal runtime image
FROM alpine:3.19

RUN apk add --no-cache ca-certificates tzdata && \
    addgroup -g 1001 -S appuser && \
    adduser -S appuser -u 1001 -G appuser

WORKDIR /app

COPY --from=builder --chown=appuser:appuser /app/app .

USER appuser

HEALTHCHECK --interval=30s --timeout=3s CMD /app/app health || exit 1

ENTRYPOINT ["/app/app"]
```

#### Node.js Applications

```dockerfile
# Multi-stage build for Node.js
FROM node:18-alpine AS builder

WORKDIR /app

# Enable pnpm (prefer pnpm over npm per guidelines)
RUN corepack enable pnpm

# Copy dependency files
COPY package.json pnpm-lock.yaml ./

# Install dependencies
RUN pnpm install --frozen-lockfile

# Copy source and build
COPY . .
RUN pnpm run build

# Production image
FROM node:18-alpine AS production

RUN apk add --no-cache tini && \
    addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001 -G nodejs

WORKDIR /app

RUN corepack enable pnpm

# Copy dependencies
COPY --from=builder /app/package.json /app/pnpm-lock.yaml ./
RUN pnpm install --prod --frozen-lockfile

# Copy built app
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist

ENV NODE_ENV=production \
    PORT=3000

USER nextjs

HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:$PORT/health || exit 1

EXPOSE $PORT

ENTRYPOINT ["tini", "--"]
CMD ["node", "dist/server.js"]
```

#### Python Applications

```dockerfile
# Multi-stage build for Python
FROM python:3.11-slim AS builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends gcc && \
    rm -rf /var/lib/apt/lists/*

# Copy and install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

# Runtime image
FROM python:3.11-slim

RUN groupadd -r appuser -g 1001 && \
    useradd -u 1001 -r -g appuser -m -s /sbin/nologin appuser

WORKDIR /app

# Copy Python packages from builder
COPY --from=builder --chown=appuser:appuser /root/.local /home/appuser/.local

# Copy application
COPY --chown=appuser:appuser . .

# Update PATH
ENV PATH=/home/appuser/.local/bin:$PATH \
    PYTHONUNBUFFERED=1

USER appuser

HEALTHCHECK --interval=30s CMD python -c "import requests; requests.get('http://localhost:8080/health')" || exit 1

CMD ["python", "app.py"]
```

### Docker Compose Best Practices

Use docker-compose.yml for multi-container applications:

```yaml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    ports:
      - "8080:8080"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgres://db:5432/myapp
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=myapp
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD_FILE=/run/secrets/db_password
    volumes:
      - db-data:/var/lib/postgresql/data
    secrets:
      - db_password
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  db-data:

secrets:
  db_password:
    file: ./secrets/db_password.txt
```

## Testing and Verification

### Local Testing

Always test Docker builds locally:

```bash
# Build the image
docker build -t myapp:latest .

# Run the container
docker run -p 8080:8080 myapp:latest

# Test with docker-compose
docker-compose up --build

# Check image size
docker images myapp:latest

# Scan for vulnerabilities (if Docker Scout available)
docker scout cves myapp:latest

# Inspect the image
docker inspect myapp:latest

# Test health check
docker inspect --format='{{"{{json .State.Health}}"}}' <container-id>
```

### Build Optimization Checks

```bash
# Check layer sizes
docker history myapp:latest

# Analyze with dive tool (if available)
dive myapp:latest

# Build with BuildKit cache
DOCKER_BUILDKIT=1 docker build --progress=plain -t myapp:latest .
```

## Implementation Strategy

**Step 1: Review Project Guidelines**
- Read `.claude/docs/guideline.md` if it exists (MANDATORY)
- Extract container-specific patterns
- Note security and deployment requirements

**Step 2: Analyze Application**
- Identify application type and dependencies
- Determine build vs runtime requirements
- Plan multi-stage build strategy

**Step 3: Create .dockerignore**
- Exclude unnecessary files
- Reduce build context size
- Improve security

**Step 4: Write Dockerfile**
- Start with appropriate base image
- Implement multi-stage build
- Optimize layer ordering
- Add security measures (non-root user)
- Include health check
- Add metadata labels

**Step 5: Test and Verify**
- Build image locally
- Test container execution
- Verify image size
- Check security scan results
- Test health check functionality

**Step 6: Document**
- Add comments explaining non-obvious choices
- Document required environment variables
- Include build and run instructions

## Common Pitfalls to Avoid

### Running as Root
```dockerfile
# Bad: No user specified (runs as root)
FROM node:18
COPY . /app
CMD ["node", "app.js"]

# Good: Non-root user
FROM node:18
RUN adduser -S appuser
USER appuser
COPY . /app
CMD ["node", "app.js"]
```

### Not Using .dockerignore
```bash
# Bad: Copying everything including node_modules, .git
COPY . .

# Good: .dockerignore excludes unnecessary files
# Then COPY . . only includes what's needed
```

### Breaking Layer Cache
```dockerfile
# Bad: Source code before dependencies (breaks cache on every code change)
COPY . .
RUN npm install

# Good: Dependencies before source code (caches dependency layer)
COPY package.json package-lock.json ./
RUN npm ci
COPY . .
```

### Not Cleaning Up in Same Layer
```dockerfile
# Bad: Cleanup in different layer (doesn't reduce size)
RUN apt-get update && apt-get install -y curl
RUN rm -rf /var/lib/apt/lists/*

# Good: Cleanup in same layer
RUN apt-get update && \
    apt-get install -y curl && \
    rm -rf /var/lib/apt/lists/*
```

### Using Shell Form Instead of Exec Form
```dockerfile
# Bad: Shell form (PID 1 is shell, not app)
CMD node app.js

# Good: Exec form (PID 1 is app, proper signal handling)
CMD ["node", "app.js"]
```

## Checklist

### Before Starting
- [ ] **Read `.claude/docs/guideline.md` if it exists** (CRITICAL)
- [ ] Analyze application and dependencies
- [ ] Identify build vs runtime requirements
- [ ] Check for existing Docker configurations

### During Implementation
- [ ] Use specific base image version (not :latest)
- [ ] Implement multi-stage build
- [ ] Create .dockerignore file
- [ ] Order layers for optimal caching
- [ ] Use `set -euo pipefail` in RUN commands
- [ ] Chain related RUN commands with &&
- [ ] Clean up in the same layer
- [ ] Create non-root user
- [ ] Set USER before CMD/ENTRYPOINT
- [ ] Use COPY instead of ADD (unless extracting tar)
- [ ] Use exec form for CMD/ENTRYPOINT
- [ ] Add HEALTHCHECK
- [ ] Add LABEL metadata
- [ ] Use ENV for runtime variables only
- [ ] Never include secrets

### After Implementation - Testing
- [ ] Build image successfully
- [ ] Image size is reasonable (check docker images)
- [ ] Container runs and responds to health checks
- [ ] Container runs as non-root (docker inspect)
- [ ] No security vulnerabilities (docker scout cves if available)
- [ ] Test build cache works (rebuild should be fast)
- [ ] Verify .dockerignore excludes expected files

## Key Principles

1. **Project Guidelines First**: Always read and follow `.claude/docs/guideline.md`
2. **Security**: Run as non-root, minimize attack surface, scan for vulnerabilities
3. **Optimization**: Multi-stage builds, layer caching, minimal base images
4. **Fail-fast**: Use `set -euo pipefail` in shell commands
5. **Simplicity**: Keep Dockerfiles clean and well-documented
6. **Reproducibility**: Pin versions, use digest pinning for critical images
7. **Maintainability**: Add health checks, labels, and clear documentation

## Version History

### v1.0.0 (2025-11-16)
- Initial Docker skill creation
- Multi-stage build best practices
- Security guidelines (non-root user, vulnerability scanning)
- Layer caching optimization techniques
- RUN command error handling with set -euo pipefail
- HEALTHCHECK, ENTRYPOINT/CMD best practices
- Language-specific examples (Go, Node.js, Python)
- Docker Compose patterns
- .dockerignore best practices
- Testing and verification procedures
